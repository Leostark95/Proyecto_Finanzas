{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "\n",
    "import a_funciones as fn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Para redes\n",
    "import tensorflow as tf\n",
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos escalados, la variable de respuesta y el scaler\n",
    "df_historicos_scaled = joblib.load('salidas/df_historicos_transf.pkl')\n",
    "y = joblib.load('salidas/v.respuesta.pkl')\n",
    "sc = joblib.load('salidas/scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historicos_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_credit = pd.read_csv('data/datos_nuevos_creditos.csv')\n",
    "df_new_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monto_credito = df_new_credit['NewLoanApplication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_new_credit['NewLoanApplication']\n",
    "del df_new_credit['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_newcredit_sc, _ = fn.procesar_datos(df_new_credit, scaler=sc)\n",
    "df_newcredit_sc.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizar selección de variables con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables con respecto a las variables y componentes\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df_historicos_scaled['Segmento'] = kmeans.fit_predict(df_historicos_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA para reducir las dimensiones a 2\n",
    "pca = PCA(n_components=2)\n",
    "df_historicos_scaled_pca = pca.fit_transform(df_historicos_scaled.drop(columns=['Segmento']))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(df_historicos_scaled_pca[:, 0], df_historicos_scaled_pca[:, 1], c=df_historicos_scaled['Segmento'], cmap='viridis', s=50, alpha=0.6)\n",
    "\n",
    "plt.title('Segmentos de Clientes usando KMeans')\n",
    "plt.xlabel('Componente Principal 1')\n",
    "plt.ylabel('Componente Principal 2')\n",
    "\n",
    "plt.colorbar(label='Segmento')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df_historicos_scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#Imprimir Tamaño de dataset, corresponden al 80,20\n",
    "print(\"Tamaño del conjunto de entrenamiento. X: \", X_train.shape,\" Y: \", y_train.shape)\n",
    "print(\"Tamaño del conjunto de validación. X: \", X_test.shape,\" Y: \", y_test.shape )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=X_train.shape[1:]),\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar el optimizador y la función de pérdida para un problema de regresión\n",
    "regression_model.compile(optimizer='adam', loss='mse', metrics=[MeanSquaredError(), RootMeanSquaredError()])\n",
    "\n",
    "# Entrenar el modelo usando el optimizador y la arquitectura definidas\n",
    "regression_model.fit(X_train, y_train, batch_size=100, epochs=10, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_mse, test_rmse = regression_model.evaluate(X_test, y_test, verbose=2)\n",
    "\n",
    "print(\"Test Mean Squared Error:\", test_mse)\n",
    "print(\"Test Root Mean Squared Error:\", test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la función de creación del modelo\n",
    "def build_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "\n",
    "    # Añadir capas ocultas con hiperparámetros para el número de unidades y la activación\n",
    "    for i in range(hp.Int('num_layers', 1, 6)):\n",
    "        model.add(tf.keras.layers.Dense(\n",
    "            units=64,  # Número fijo de unidades en cada capa\n",
    "            activation=hp.Choice('activation', ['relu', 'tanh']),\n",
    "            kernel_initializer=hp.Choice('init_mode', ['uniform', 'he_normal'])\n",
    "        ))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compilar el modelo con hiperparámetros para el optimizador\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='mse',\n",
    "        metrics=[tf.keras.metrics.MeanSquaredError(), tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld'\n",
    ")\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros\n",
    "tuner.search(X_train, y_train, epochs=10, validation_data=(X_test, y_test), batch_size=100)\n",
    "\n",
    "# Obtener los mejores hiperparámetros\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "\n",
    "# Mostrar los mejores hiperparámetros\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(f\"- Number of layers: {best_hps.get('num_layers')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones con el modelo entrenado\n",
    "y_pred_nuevos = regression_model.predict(df_newcredit_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Residuales\n",
    "\n",
    "# Obtener las predicciones del modelo en los datos de prueba\n",
    "y_pred = regression_model.predict(X_test).flatten()\n",
    "\n",
    "# Calcular los residuales\n",
    "residuales = y_test - y_pred\n",
    "\n",
    "# Histograma de los residuales\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(residuales, bins=20, edgecolor='k')\n",
    "plt.title('Histograma de Residuales')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de dispersión de los residuales vs. predicciones\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuales, alpha=0.5)\n",
    "plt.title('Residuales vs. Predicciones')\n",
    "plt.xlabel('Predicciones')\n",
    "plt.ylabel('Residuales')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de dispersión de los residuales vs. el valor verdadero\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, residuales, alpha=0.5)\n",
    "plt.title('Residuales vs. Valor Verdadero')\n",
    "plt.xlabel('Valor Verdadero')\n",
    "plt.ylabel('Residuales')\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el histograma de las predicciones\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(y_pred_nuevos, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Histograma de Predicciones')\n",
    "plt.xlabel('Valor Predicho')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predic = df_new_credit.copy()\n",
    "df_predic['NoPaidPer'] = y_pred_nuevos\n",
    "df_predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las predicciones que están entre 0 y 0.1\n",
    "tasa1 = df_predic.loc[(df4['predicciones'] >= 0) & (df_predic['predicciones'] < 0.15)]\n",
    "# Filtrar las predicciones que están entre 0 y 0.1\n",
    "tasa2 = df_predic.loc[(df_predic['predicciones'] >= 0.15)]\n",
    "\n",
    "print(tasa1.shape)\n",
    "print(tasa2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
